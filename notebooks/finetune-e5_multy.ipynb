{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10042263,"sourceType":"datasetVersion","datasetId":6186291}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, AutoTokenizer, AutoModelForSequenceClassification","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-30T22:52:29.286376Z","iopub.execute_input":"2024-11-30T22:52:29.286741Z","iopub.status.idle":"2024-11-30T22:52:29.292080Z","shell.execute_reply.started":"2024-11-30T22:52:29.286711Z","shell.execute_reply":"2024-11-30T22:52:29.291152Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"neg = pd.read_csv(\"/kaggle/input/wb-sch-p2/train_neg.csv\")\npos = pd.read_csv(\"/kaggle/input/wb-sch-p2/train_pos.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T22:52:29.451521Z","iopub.execute_input":"2024-11-30T22:52:29.451825Z","iopub.status.idle":"2024-11-30T22:52:29.693222Z","shell.execute_reply.started":"2024-11-30T22:52:29.451800Z","shell.execute_reply":"2024-11-30T22:52:29.692230Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"data = pd.concat([neg, pos])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T22:52:29.694970Z","iopub.execute_input":"2024-11-30T22:52:29.695363Z","iopub.status.idle":"2024-11-30T22:52:29.703749Z","shell.execute_reply.started":"2024-11-30T22:52:29.695290Z","shell.execute_reply":"2024-11-30T22:52:29.702925Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"data['desc'] = data.apply(lambda x: x if len(x.desk) < 350 else x.desk[:350], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T22:52:29.857294Z","iopub.execute_input":"2024-11-30T22:52:29.857641Z","iopub.status.idle":"2024-11-30T22:52:29.898013Z","shell.execute_reply.started":"2024-11-30T22:52:29.857613Z","shell.execute_reply":"2024-11-30T22:52:29.897186Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"data = data.sample(frac=1).reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T22:52:30.070102Z","iopub.execute_input":"2024-11-30T22:52:30.070729Z","iopub.status.idle":"2024-11-30T22:52:30.078665Z","shell.execute_reply.started":"2024-11-30T22:52:30.070696Z","shell.execute_reply":"2024-11-30T22:52:30.077720Z"}},"outputs":[],"execution_count":65},{"cell_type":"code","source":"data['qad'] = data[\"Question\"].astype(str) + \"/n\" + data[\"desc\"].astype(str)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T22:52:30.254508Z","iopub.execute_input":"2024-11-30T22:52:30.254844Z","iopub.status.idle":"2024-11-30T22:52:30.274475Z","shell.execute_reply.started":"2024-11-30T22:52:30.254814Z","shell.execute_reply":"2024-11-30T22:52:30.273866Z"}},"outputs":[],"execution_count":66},{"cell_type":"code","source":"import re\ndef clean_text(text):\n    text = text.lower()\n\n    text = re.sub(r'[^a-zA-Zа-яА-Я0-9\\s]', '', text)\n    \n    text = re.sub(r'\\s+', ' ', text).strip()\n    \n    return text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T22:52:30.414644Z","iopub.execute_input":"2024-11-30T22:52:30.415564Z","iopub.status.idle":"2024-11-30T22:52:30.420620Z","shell.execute_reply.started":"2024-11-30T22:52:30.415512Z","shell.execute_reply":"2024-11-30T22:52:30.419782Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"data['qad'] = data['qad'].apply(clean_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T22:52:30.630895Z","iopub.execute_input":"2024-11-30T22:52:30.631268Z","iopub.status.idle":"2024-11-30T22:52:30.735241Z","shell.execute_reply.started":"2024-11-30T22:52:30.631239Z","shell.execute_reply":"2024-11-30T22:52:30.734430Z"}},"outputs":[],"execution_count":68},{"cell_type":"code","source":"class CustomDataset(Dataset):\n  def __init__(self, questions, labels, tokenizer, max_length):\n    self.questions = questions\n    self.labels = labels\n    self.tokenizer = tokenizer\n    self.max_length = max_length\n\n  def __len__(self):\n    return len(self.questions)\n\n  def __getitem__(self, idx):\n    text = str(self.questions[idx])\n    label = self.labels[idx]\n\n    encoding = self.tokenizer.encode_plus(\n               text,\n               add_special_tokens=True,\n               max_length=self.max_length,\n               return_token_type_ids=False,\n               padding='max_length',\n               return_attention_mask=True,\n               return_tensors='pt',\n               truncation=True\n           )\n\n    return {\n            'text': text,\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'labels': torch.tensor(label, dtype=torch.long)\n           }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T22:52:30.920156Z","iopub.execute_input":"2024-11-30T22:52:30.920776Z","iopub.status.idle":"2024-11-30T22:52:30.928003Z","shell.execute_reply.started":"2024-11-30T22:52:30.920741Z","shell.execute_reply":"2024-11-30T22:52:30.927102Z"}},"outputs":[],"execution_count":69},{"cell_type":"code","source":"def create_data_loader(df, tokenizer, max_length, batch_size):\n  ds = CustomDataset(\n           questions=df.qad.to_numpy(),\n           labels=df.label.to_numpy(),\n           tokenizer=tokenizer,\n           max_length=max_length\n       )\n  return DataLoader(ds, batch_size=batch_size, num_workers=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T22:52:32.149690Z","iopub.execute_input":"2024-11-30T22:52:32.150393Z","iopub.status.idle":"2024-11-30T22:52:32.155411Z","shell.execute_reply.started":"2024-11-30T22:52:32.150359Z","shell.execute_reply":"2024-11-30T22:52:32.154516Z"}},"outputs":[],"execution_count":70},{"cell_type":"code","source":"model_name =\"intfloat/multilingual-e5-base\" #\"cointegrated/LaBSE-en-ru\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n# model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T22:52:32.156912Z","iopub.execute_input":"2024-11-30T22:52:32.157199Z","iopub.status.idle":"2024-11-30T22:52:33.962950Z","shell.execute_reply.started":"2024-11-30T22:52:32.157173Z","shell.execute_reply":"2024-11-30T22:52:33.962001Z"}},"outputs":[{"name":"stderr","text":"Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at intfloat/multilingual-e5-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":71},{"cell_type":"code","source":"data.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T22:52:33.964921Z","iopub.execute_input":"2024-11-30T22:52:33.965270Z","iopub.status.idle":"2024-11-30T22:52:33.971663Z","shell.execute_reply.started":"2024-11-30T22:52:33.965230Z","shell.execute_reply":"2024-11-30T22:52:33.970732Z"}},"outputs":[{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"(2512, 8)"},"metadata":{}}],"execution_count":72},{"cell_type":"code","source":"val = data.sample(400, random_state=42)\ntrain = data.drop(val.index)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T22:52:33.972617Z","iopub.execute_input":"2024-11-30T22:52:33.972953Z","iopub.status.idle":"2024-11-30T22:52:33.984580Z","shell.execute_reply.started":"2024-11-30T22:52:33.972912Z","shell.execute_reply":"2024-11-30T22:52:33.983860Z"}},"outputs":[],"execution_count":73},{"cell_type":"code","source":"BATCH_SIZE = 16\nMAX_LENGTH = 512\n\ntrain_data_loader = create_data_loader(train, tokenizer, MAX_LENGTH, BATCH_SIZE)\nval_data_loader = create_data_loader(val, tokenizer, MAX_LENGTH, BATCH_SIZE)\n\ntraining_args = TrainingArguments(\n       output_dir='./results',\n       num_train_epochs=4,\n       per_device_train_batch_size=BATCH_SIZE,\n       per_device_eval_batch_size=BATCH_SIZE,\n       warmup_steps=500,\n       weight_decay=0.01,\n       logging_dir='./logs',\n       logging_steps=10,\n       eval_strategy='steps'\n   )\n\ntrainer = Trainer(\n       model=model,\n       args=training_args,\n       train_dataset=train_data_loader.dataset,\n       eval_dataset=val_data_loader.dataset\n   )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T22:52:33.985995Z","iopub.execute_input":"2024-11-30T22:52:33.986241Z","iopub.status.idle":"2024-11-30T22:52:34.478123Z","shell.execute_reply.started":"2024-11-30T22:52:33.986217Z","shell.execute_reply":"2024-11-30T22:52:34.477218Z"}},"outputs":[],"execution_count":74},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T22:52:35.269476Z","iopub.execute_input":"2024-11-30T22:52:35.269826Z","iopub.status.idle":"2024-11-30T23:04:52.594371Z","shell.execute_reply.started":"2024-11-30T22:52:35.269796Z","shell.execute_reply":"2024-11-30T23:04:52.593356Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='264' max='264' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [264/264 12:14, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>0.672700</td>\n      <td>0.680199</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.673100</td>\n      <td>0.669578</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.664100</td>\n      <td>0.665450</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.677800</td>\n      <td>0.656854</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.652000</td>\n      <td>0.644860</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.662000</td>\n      <td>0.632265</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.628100</td>\n      <td>0.611201</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.542400</td>\n      <td>0.612993</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.636300</td>\n      <td>0.546514</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.568600</td>\n      <td>0.513093</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>0.515600</td>\n      <td>0.444488</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.462200</td>\n      <td>0.351663</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>0.363000</td>\n      <td>0.272924</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.290000</td>\n      <td>0.255227</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.242400</td>\n      <td>0.247596</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.210400</td>\n      <td>0.257753</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>0.295800</td>\n      <td>0.234679</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.245000</td>\n      <td>0.215407</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>0.197300</td>\n      <td>0.221271</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.188000</td>\n      <td>0.203694</td>\n    </tr>\n    <tr>\n      <td>210</td>\n      <td>0.156100</td>\n      <td>0.203130</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>0.112700</td>\n      <td>0.211676</td>\n    </tr>\n    <tr>\n      <td>230</td>\n      <td>0.165500</td>\n      <td>0.189373</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>0.143400</td>\n      <td>0.218112</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.099400</td>\n      <td>0.195459</td>\n    </tr>\n    <tr>\n      <td>260</td>\n      <td>0.138100</td>\n      <td>0.199395</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=264, training_loss=0.39008257425192633, metrics={'train_runtime': 736.634, 'train_samples_per_second': 11.468, 'train_steps_per_second': 0.358, 'total_flos': 2222762195681280.0, 'train_loss': 0.39008257425192633, 'epoch': 4.0})"},"metadata":{}}],"execution_count":75},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\ndef tokenize_question(question, tokenizer, max_length=512):\n    return tokenizer(\n        [question],\n        padding=True,\n        truncation=True,\n        return_tensors=\"pt\",\n        max_length=max_length\n    )\n\ndef predict(question):\n    inputs = tokenize_question(question, tokenizer)\n    inputs = {key: value.to(device) for key, value in inputs.items()}\n    with torch.no_grad():\n        outputs = model(**inputs)\n        logits = outputs.logits\n        \n    predictions = torch.argmax(logits, dim=-1).cpu().numpy()\n    probabilities = torch.softmax(logits, dim=-1).cpu().numpy()\n    return predictions\n    \n    \n    \n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T23:04:52.596259Z","iopub.execute_input":"2024-11-30T23:04:52.596624Z","iopub.status.idle":"2024-11-30T23:04:52.608293Z","shell.execute_reply.started":"2024-11-30T23:04:52.596586Z","shell.execute_reply":"2024-11-30T23:04:52.607442Z"}},"outputs":[],"execution_count":76},{"cell_type":"code","source":"val_neg = pd.read_csv(\"/kaggle/input/wb-sch-p2/valid_250_neg.csv\")\nval_pos = pd.read_csv(\"/kaggle/input/wb-sch-p2/valid_250_pos.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T23:04:52.609552Z","iopub.execute_input":"2024-11-30T23:04:52.609879Z","iopub.status.idle":"2024-11-30T23:04:52.697227Z","shell.execute_reply.started":"2024-11-30T23:04:52.609832Z","shell.execute_reply":"2024-11-30T23:04:52.696229Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"valid = pd.concat([val_neg, val_pos])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T23:04:52.699486Z","iopub.execute_input":"2024-11-30T23:04:52.699839Z","iopub.status.idle":"2024-11-30T23:04:52.706416Z","shell.execute_reply.started":"2024-11-30T23:04:52.699799Z","shell.execute_reply":"2024-11-30T23:04:52.705333Z"}},"outputs":[],"execution_count":78},{"cell_type":"code","source":"valid['desc'] = valid.apply(lambda x: x if len(x.desk) < 350 else x.desk[:350], axis=1)\nvalid['qad'] = valid[\"Question\"].astype(str) + \"/n\" + valid[\"desc\"].astype(str)\nvalid['qad'] = valid['qad'].apply(clean_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T23:04:52.707506Z","iopub.execute_input":"2024-11-30T23:04:52.707743Z","iopub.status.idle":"2024-11-30T23:04:52.800214Z","shell.execute_reply.started":"2024-11-30T23:04:52.707719Z","shell.execute_reply":"2024-11-30T23:04:52.799257Z"}},"outputs":[],"execution_count":79},{"cell_type":"code","source":"valid['pred'] = valid.apply(lambda x: predict(x.qad)[0] ,axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T23:04:52.801436Z","iopub.execute_input":"2024-11-30T23:04:52.801897Z","iopub.status.idle":"2024-11-30T23:04:58.289686Z","shell.execute_reply.started":"2024-11-30T23:04:52.801842Z","shell.execute_reply":"2024-11-30T23:04:58.288744Z"}},"outputs":[],"execution_count":80},{"cell_type":"code","source":"valid['pred']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T23:04:58.290807Z","iopub.execute_input":"2024-11-30T23:04:58.291143Z","iopub.status.idle":"2024-11-30T23:04:58.299320Z","shell.execute_reply.started":"2024-11-30T23:04:58.291109Z","shell.execute_reply":"2024-11-30T23:04:58.298514Z"}},"outputs":[{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"0      0\n1      0\n2      0\n3      0\n4      1\n      ..\n245    1\n246    1\n247    1\n248    1\n249    1\nName: pred, Length: 500, dtype: int64"},"metadata":{}}],"execution_count":81},{"cell_type":"code","source":"from sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nprecision_score(valid['label'], valid['pred']), recall_score(valid['label'], valid['pred'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T23:04:58.300546Z","iopub.execute_input":"2024-11-30T23:04:58.300882Z","iopub.status.idle":"2024-11-30T23:05:02.897582Z","shell.execute_reply.started":"2024-11-30T23:04:58.300845Z","shell.execute_reply":"2024-11-30T23:05:02.896687Z"}},"outputs":[{"execution_count":82,"output_type":"execute_result","data":{"text/plain":"(0.9263565891472868, 0.956)"},"metadata":{}}],"execution_count":82},{"cell_type":"code","source":"hf_token = \"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\"\nhf_username = \"Hvixze\"\nmodel.push_to_hub(f\"{hf_username}/e5_base_wb_p2_4ep\", token = hf_token) # Online saving\ntokenizer.push_to_hub(f\"{hf_username}/e5_base_wb_p2_4ep\", token = hf_token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T23:12:45.136713Z","iopub.execute_input":"2024-11-30T23:12:45.137066Z","iopub.status.idle":"2024-11-30T23:13:15.052207Z","shell.execute_reply.started":"2024-11-30T23:12:45.137040Z","shell.execute_reply":"2024-11-30T23:13:15.051450Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52aea26d264c4a9c8c34331ebfef2e29"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a383504745e4dc5adc8839eba0a36e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06900f79f4a945b7a675bfb588d1abf3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fae9548f427541daadb23760d3d83376"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e8834c2382f4b7aac65016163feabb9"}},"metadata":{}},{"execution_count":83,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/Hvixze/e5_base_wb_p2_4ep/commit/f5e5d90833e1a6c30ef828243e306faf23928dd0', commit_message='Upload tokenizer', commit_description='', oid='f5e5d90833e1a6c30ef828243e306faf23928dd0', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Hvixze/e5_base_wb_p2_4ep', endpoint='https://huggingface.co', repo_type='model', repo_id='Hvixze/e5_base_wb_p2_4ep'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":83},{"cell_type":"code","source":" ","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}